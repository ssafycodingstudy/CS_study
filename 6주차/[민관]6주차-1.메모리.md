### 메인 메모리

- CPU가 직접 접근할 수 있는 메모리
- 프로그램이 실행되려면 해당 프로그램이 복사되어 메모리에 올라와야 함, 이를 프로세스
- CPU 는 연산 수행한 후 메인 메모리에 데이터를 저장하거나 필요한 데이터를 요구

![1](https://user-images.githubusercontent.com/44665707/151324519-0eb04d9e-6646-4e86-b312-97b2cc26a8e0.PNG)



### MMU(Memory Management Unit)

- MMU는 논리 주소를 물리 주소로 변환시켜줌
- 메모리 보호나 캐시 관리 등 CPU가 메모리에 접근하는 것을 관리해주는 하드웨어
- 메모리 공간이 한정적이기 때문에, 사용자에게 더 많은 메모리를 제공하고 있는 듯 속이기 위한 '가상 주소'라는 개념 등장
- 이 가상 주소를 실제 물리 주소로 빠르게 변환시켜야 하는데 이를 MMU가 도와줌



### MMU의 메모리 보호

- 프로세스는 독립적인 메모리 공간을 가져야 하며, 다른 공간을 침범해선 안됨
- 한 프로세스에게 주소 영역을 설정하고, 잘못된 접근이 오면 이를 보호해야 함



### 메모리 과할당

- 실제 메모리 사이즈보다 더 큰 사이즈의 메모리를 프로세스에 할당한 상황
- 페이징 기법과 같은 메모리 관리 기법은 사용자가 큰 메모리를 사용하는 것처럼 느끼도록 눈속임을 통해 메모리를 할당, 이때 사용하는 것이 가상 메모리 기법



### 페이지 교체

- 교체(Swapping) 기법 중 하나의 프로세스를 swap out해서 빈 프레임을 확보하는 것



### 페이지 교체 기법 과정

1. 페이지 부재(폴트) 발생
2. 페이지 폴트를 발생시킨 페이지 위치를 디스크에서 탐색
3. 메모리에 빈 프레임 있는지 확인
4. 빈 프레임이 없으면 희생 프레임을 선정해 디스크에 변경 사항 기록하고 페이지 테이블 업데이트
5. 빈 프레임에 피이지 폴트가 발생한 페이지를 올리고, 페이지 테이블 업데이트

=> 페이지 교체가 일어나도 사용자가 못느끼도록 프로세스를 계속 수행시켜야함, 즉 오버헤드 감소 시켜야 함

- 페이지 교체가 많이 이루어진다면 오버헤드 문제가 발생함
  - 접근 횟수 줄이기
  - 페이지 교체 알고리즘 사용



### 캐시 메모리

- 주 기억장치에 저장된 내용의 일부를 임시로 저장해두는 기억장치
- CPU와 메인메모리 간의 성능 차이에 대한 성능 저하를 줄이기 위한 대안
- 어떤 데이터에 대해 재접근 할때 그 데이터를 캐시 메모리에 저장해놨다면 메인 메모리까지 접근할 필요 없음



### 캐싱 과정

1. CPU에서 주소를 전달, 해당 명령이 캐시 기억장치에 존재하는지 확인
2. 존재하면 해당 명령어를 CPU에게 전달
3. 존재하지 않는다면 MISS
4. 주기억장치로 접근
5. 해당 명령어를 가진 데이터 인출
6. 해당 명령어 데이터를 캐시에 저장
7. 해당 명령어를 CPU로 전송

=> 비용은 많이 줄일 수 있지만, 효율적 활용 위해 적중률을 극대화 해야함. 이때 사용되는 것이 지역성의 원리



### 지역성의 원리

- 기억 장치 내의 데이터를 균등하게 접근하는 것이 아니라, 어떠한 순간에 특정한 부분을 집중적으로 접근하는 특성
- 시간 지역성 : 최근에 참조된 주소의 내용은 곧 다음에도 참조되는 특성
- 공간 지역성 : 실제 프로그램이 참조한 주소와 인접한 주소의 내용이 다시 참조되는 특성